# ==============================================================================
# Local Development Environment Variables for brAInwav MAS Platform
# ==============================================================================
# INSTRUCTIONS:
# 1. Copy this file to a new file named '.env' in the project root.
# 2. Fill in the placeholder values below.
# 3. The '.env' file is listed in .gitignore and will NOT be committed.
#
# Variables are grouped by the application/service that primarily consumes them.

# --- Core Monorepo Settings (Used by docker-compose, root scripts) ---
# Ensure these are set for Docker Compose and general script execution.
POSTGRES_DB=brainwav_dev
POSTGRES_USER=admin
POSTGRES_PASSWORD=your_strong_local_password  # Change this to a secure password

# --- FastAPI Backend Application Settings (apps/api/) ---
# These variables are primarily consumed by the apps/api/src/main.py AppSettings.
# The DATABASE_URL is constructed here but its components are defined above.
DATABASE_URL="postgresql+asyncpg://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB}"
API_DEBUG=True  # Set to 'true' for development, 'false' for production (main.py)
LOG_LEVEL=debug  # Application logging level (main.py)
# Security & Secrets: The application will fail to start if this is not set.
# Generate a strong, random string: openssl rand -hex 32 or Python's secrets.token_hex(32)
API_SECRET_KEY=your_super_secret_application_key_here

# --- Frontend Application Settings (apps/web/) ---
# These variables are exposed to the client-side Next.js application (via next.config.js).
# NEXT_PUBLIC_ prefix is mandatory for client-side exposure.
NEXT_PUBLIC_API_URL=http://localhost:8000  # The URL where your FastAPI backend is running

# --- Global AI Provider Configuration (apps/api/src/core/integrations/providers/settings.py) ---
# Default timeout in seconds for all AI provider API calls.
AI_PROVIDER_TIMEOUT_SECONDS=60

# --- OpenAI Provider Configuration (OpenAISettings) ---
# Required for OpenAI integration. Fetch from 1Password via fetch_secrets.py.
OPENAI_API_KEY=
# Optional: Override default model. Default in settings.py: gpt-4o
OPENAI_MODEL_NAME=gpt-4o-mini
# Optional: OpenAI Organization ID
OPENAI_ORGANIZATION=org-your_org_id
# Optional: Default temperature for generation. Default in settings.py: 0.7 (0.0-2.0)
OPENAI_DEFAULT_TEMPERATURE=0.7
# Optional: Max retries for failed API calls. Default in settings.py: 3
OPENAI_MAX_RETRIES=3

# --- Google AI Provider Configuration (GoogleAISettings) ---
# Required for Google AI integration. Fetch from 1Password via fetch_secrets.py.
GOOGLE_AI_API_KEY=
# Required: Google Cloud Project ID for authentication and billing.
GOOGLE_CLOUD_PROJECT_ID=your-gcp-project-id
# Optional: Google Cloud region. Default in settings.py: us-central1
GOOGLE_CLOUD_REGION=us-central1
# Optional: Override default model. Default in settings.py: gemini-1.5-pro-latest
GOOGLE_AI_MODEL_NAME=gemini-1.5-flash-latest
# Optional: API request quota limit per minute. Default in settings.py: 60
GOOGLE_AI_QUOTA_LIMIT_PER_MINUTE=60

# --- Anthropic Provider Configuration (AnthropicSettings) ---
# Required for Anthropic integration. Fetch from 1Password via fetch_secrets.py.
ANTHROPIC_API_KEY=
# Optional: Override default model. Default in settings.py: claude-3-opus-20240229
ANTHROPIC_MODEL_NAME=claude-3-sonnet-20240229
# Optional: Anthropic API version. Default in settings.py: 2023-06-01
ANTHROPIC_API_VERSION=2023-06-01

# --- Ollama Provider Configuration (OllamaSettings) ---
# Ollama usually runs locally without an API key. Its base URL is typically its host.
# Optional: API key for Ollama if required (e.g., for remote/secured Ollama instances)
OLLAMA_API_KEY=
# Base URL for your Ollama instance. Default in settings.py: http://localhost:11434
# If running via docker-compose, this will likely be the service name, e.g., 'http://ollama:11434'
OLLAMA_BASE_URL=http://ollama:11434
# Optional: Override default model. Default in settings.py: llama2
OLLAMA_MODEL_NAME=llama2
# Optional: Request timeout for Ollama. Default in settings.py: 120 (seconds)
OLLAMA_TIMEOUT_SECONDS=120
