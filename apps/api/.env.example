# FastAPI Backend Environment Configuration
# Copy this file to .env and fill in your actual values.
# Values set here will override defaults defined in code.

# --- Application Configuration (apps/api/src/main.py -> AppSettings) ---
# Your unique secret key for security purposes (e.g., signing tokens).
# Generate a strong, random string: openssl rand -hex 32 or Python's secrets.token_hex(32)
API_SECRET_KEY=your_secret_key_here_for_fastapi_security
API_DEBUG=true  # Set to 'true' for development, 'false' for production
API_HOST=0.0.0.0
API_PORT=8000
# CORS_ORIGINS: Configure allowed origins in main.py, typically not via .env.example list

# --- Database Configuration (apps/api/src/main.py -> AppSettings) ---
POSTGRES_DB=brainwav_db
POSTGRES_USER=brainwav_user
POSTGRES_PASSWORD=your_secure_db_password_here
DATABASE_URL=postgresql://brainwav_user:your_secure_db_password_here@db:5432/brainwav_db

# --- Global AI Provider Configuration (apps/api/src/core/integrations/providers/settings.py) ---
# Default timeout for all AI provider API calls in seconds.
AI_PROVIDER_TIMEOUT_SECONDS=60

# --- OpenAI Provider Configuration (OpenAISettings) ---
# Required for OpenAI integration
OPENAI_API_KEY=your_openai_api_key_here
# Optional: Override default model. Default in code: gpt-4o
OPENAI_MODEL_NAME=gpt-4o-mini
# Optional: Custom base URL if using a proxy or different endpoint
OPENAI_BASE_URL=https://api.openai.com/v1/
# Optional: OpenAI Organization ID
OPENAI_ORGANIZATION=org-your_org_id
# Optional: Default temperature for generation. Default in code: 0.7 (0.0-2.0)
OPENAI_DEFAULT_TEMPERATURE=0.7
# Optional: Max retries for failed API calls. Default in code: 3
OPENAI_MAX_RETRIES=3

# --- Google AI Provider Configuration (GoogleAISettings) ---
# Required for Google AI integration
GOOGLE_AI_API_KEY=your_google_ai_api_key_here
# Required: Google Cloud Project ID associated with your API Key/Service Account
GOOGLE_CLOUD_PROJECT_ID=your-gcp-project-id
# Optional: Google Cloud region. Default in code: us-central1
GOOGLE_CLOUD_REGION=us-central1
# Optional: Override default model. Default in code: gemini-1.5-pro-latest
GOOGLE_AI_MODEL_NAME=gemini-1.5-flash-latest
# Optional: Custom base URL if using a proxy. Typically auto-constructed.
GOOGLE_AI_BASE_URL=
# Optional: API request quota limit per minute. Default in code: 60
GOOGLE_AI_QUOTA_LIMIT_PER_MINUTE=60

# --- Anthropic Provider Configuration (AnthropicSettings) ---
# Required for Anthropic integration
ANTHROPIC_API_KEY=your_anthropic_api_key_here
# Optional: Override default model. Default in code: claude-3-opus-20240229
ANTHROPIC_MODEL_NAME=claude-3-sonnet-20240229
# Optional: Custom base URL if using a proxy. Default in code: https://api.anthropic.com/v1/
ANTHROPIC_BASE_URL=https://api.anthropic.com/v1/
# Optional: Anthropic API version. Default in code: 2023-06-01
ANTHROPIC_API_VERSION=2023-06-01

# --- Ollama Provider Configuration (OllamaSettings) ---
# Optional: API key for Ollama if required (e.g., for remote/secured Ollama instances)
OLLAMA_API_KEY=
# Optional: Base URL for your Ollama instance. Default in code: http://localhost:11434
OLLAMA_BASE_URL=http://ollama:11434
# Optional: Override default model. Default in code: llama2
OLLAMA_MODEL_NAME=llama2
# Optional: Request timeout for Ollama. Default in code: 120 (seconds)
OLLAMA_TIMEOUT_SECONDS=120

# --- Logging Configuration ---
# Set the desired logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO
